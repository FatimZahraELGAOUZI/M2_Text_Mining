req=paste(req,"CREATE TABLE ref_departement(                              ")
req=paste(req,"  nom_departement VARCHAR(100),                            ")
req=paste(req,"  code_departement VARCHAR(6),                             ")
req=paste(req,"  code_region VARCHAR(5),                                      ")
req=paste(req,"  CONSTRAINT PK_ref_departement PRIMARY KEY (code_departement), ")
req=paste(req,"  FOREIGN KEY fk_region  (code_region)                         ")
req=paste(req,"  REFERENCES ref_regions (code_region)                       ")
req=paste(req,");                                                             ")
execute_requete(connexion,req)
req=""
req=paste(req,"CREATE TABLE ref_communes(  ")
req=paste(req,"  id_commune INT PRIMARY KEY NOT NULL AUTO_INCREMENT,                 ")
req=paste(req,"  nom_commune VARCHAR(100),                                   ")
req=paste(req,"  code_commune VARCHAR(6),                                     ")
req=paste(req,"  code_departement VARCHAR(5),                                 ")
req=paste(req,"  code_postal VARCHAR(5),                                     ")
req=paste(req,"  FOREIGN KEY fk_departements  (code_departement)              ")
req=paste(req,"  REFERENCES ref_departement (code_departement)                ")
req=paste(req,");                                                             ")
execute_requete(connexion,req)
req="ALTER TABLE ref_communes ADD INDEX (code_postal)"
execute_requete(connexion,req)
req="ALTER TABLE ref_communes ADD INDEX (code_commune)"
execute_requete(connexion,req)
req=""
req=paste(req,"CREATE TABLE contrat(                                         ")
req=paste(req,"  id_contrat VARCHAR(10),               ")
req=paste(req,"  type_contrat VARCHAR(30),                                   ")
req=paste(req,"  libelle_contrat VARCHAR(300),                               ")
req=paste(req,"  CONSTRAINT PK_contrat PRIMARY KEY (id_contrat)              ")
req=paste(req,");                                                            ")
execute_requete(connexion,req)
req=""
req=paste(req,"CREATE TABLE poste(                                           ")
req=paste(req,"  id_poste VARCHAR(10),                 ")
req=paste(req,"  code_rome VARCHAR(10),                                      ")
req=paste(req,"  libelle_rome TEXT,                                          ")
req=paste(req,"  appellation_libelle TEXT,                                   ")
req=paste(req,"  CONSTRAINT PK_poste PRIMARY KEY (id_poste)                  ")
req=paste(req,");                                                            ")
execute_requete(connexion,req)
req=""
req=paste(req,"CREATE TABLE experience(                                      ")
req=paste(req,"  id_experience VARCHAR(10),            ")
req=paste(req,"  libelle_experience TEXT,                                    ")
req=paste(req,"  experience_exigee varchar(10),                              ")
req=paste(req,"  CONSTRAINT PK_experience PRIMARY KEY (id_experience)        ")
req=paste(req,");                                                            ")
execute_requete(connexion,req)
req=""
req=paste(req,"CREATE TABLE secteur_activite(                                ")
req=paste(req,"  id_secteur VARCHAR(10),               ")
req=paste(req,"  libelle_secteur TEXT,                                       ")
req=paste(req,"  secteur_activite TEXT,                                      ")
req=paste(req,"  CONSTRAINT PK_secteur_activite PRIMARY KEY (id_secteur)     ")
req=paste(req,");                                                            ")
execute_requete(connexion,req)
req=""
req=paste(req,"CREATE TABLE Offre_emploi(                                    ")
req=paste(req,"  id_offre VARCHAR(10),                 ")
req=paste(req,"  id_contrat VARCHAR(10),                                       ")
req=paste(req,"  id_poste VARCHAR(10),                                         ")
req=paste(req,"  id_experience VARCHAR(10),                                    ")
req=paste(req,"  id_secteur VARCHAR(10),                                       ")
req=paste(req,"  categorie VARCHAR(60),                                       ")
req=paste(req,"  date_creation DATETIME,                                     ")
req=paste(req,"  intitule_offre VARCHAR(300),                                ")
req=paste(req,"  description_offre TEXT,                                     ")
req=paste(req,"  salaire varchar(200),                                     ")
req=paste(req,"  nom_entreprise varchar(200),                                     ")
req=paste(req,"  codeCommune varchar(5),                                     ")
req=paste(req,"  CONSTRAINT PK_offre PRIMARY KEY (id_offre),                 ")
req=paste(req,"  FOREIGN KEY (id_contrat)                                    ")
req=paste(req,"  REFERENCES contrat (id_contrat),                            ")
req=paste(req,"  FOREIGN KEY (id_poste)                                      ")
req=paste(req,"  REFERENCES poste (id_poste),                                ")
req=paste(req,"  FOREIGN KEY (id_experience)                                 ")
req=paste(req,"  REFERENCES experience (id_experience)	,                    ")
req=paste(req,"  FOREIGN KEY (id_secteur)                                    ")
req=paste(req,"  REFERENCES secteur_activite (id_secteur)		                 ")
# problème de saisie de code commune: des fois les employeurs mettent le code postal
# au lieu de code commune
#req=paste(req,"  FOREIGN KEY  (codeCommune)                                    ")
#req=paste(req,"  REFERENCES ref_communes (code_commune)		                 ")
req=paste(req,")                                                              ")
execute_requete(connexion,req)
fermerConnexion(connexion)
}
#---------------------------- fonction finale --------------------------------------------#
# renvoie la date de la dernière mise à jour de la base ou NA
# à utiliser au moment de recupèration des données de l'API
date_last_update<- function(connexion){
date_last_update=DBI::dbGetQuery(connexion, "select max(date_creation) from offre_emploi")
maj = date_last_update[[1]]
if(is.na(maj)){
return (NA)
}else{
maj = as.POSIXct(maj, format="%Y-%m-%d %H:%M:%S", tz="UTC")
maj = format(maj, "%Y-%m-%dT%H:%M:%OSZ")
}
return (maj)
}
##---------------------------- requetage API --------------------------------####
Add_categorie <- function(df){
df$intitule = toupper(df$intitule)
df$categorie = "AUTRE"
df$categorie[grep("DATA SCIENTIST", df$intitule)] = "DATA SCIENTIST"
df$categorie[grep("DATA ANALYST", df$intitule)] = "DATA ANALYST"
df$categorie[grep("DATA ENGINEER", df$intitule)] = "DATA ENGINEER"
return(df)
}
# fait appel à l'API des referentiels des région pour alimenter la base
# fonction appelée par une autre
mise_a_jour_regions<-function (connexion, token){
url="https://api.emploi-store.fr/partenaire/offresdemploi/v2/referentiel/regions"
request_data <-httr::GET(url,add_headers(Authorization = token))
data= jsonlite::fromJSON(httr::content(request_data,as="text", encoding = "UTF-8"), flatten =TRUE)
for(i in 1:nrow(data)) {
insert_into_regions (connexion, data[i,"libelle"], data[i,"code"])
}
}
# fait appel à l'API des referentiels des departements pour alimenter la base
# fonction appelée par une autre
mise_a_jour_departement<-function (connexion,token){
url="https://api.emploi-store.fr/partenaire/offresdemploi/v2/referentiel/departements"
request_data <- httr::GET(url,add_headers(Authorization = token))
data = jsonlite::fromJSON(httr::content(request_data,as="text", encoding = "UTF-8"), flatten =TRUE)
for(i in 1:nrow(data)) {
insert_into_departements (connexion, data[i,"libelle"], data[i,"code"], data[i,"region.code"] )
}
}
# fait appel à l'API des referentiels des communes pour alimenter la base
# fonction appelée par une autre
mise_a_jour_communes<-function (connexion, token){
url="https://api.emploi-store.fr/partenaire/offresdemploi/v2/referentiel/communes"
request_data <- httr::GET(url,add_headers(Authorization = token))
data = fromJSON(content(request_data,as="text", encoding = "UTF-8"), flatten =TRUE)
#exclure les departements qui ne sont pas reférencées dans l'API departements
data = subset(data, !(codeDepartement %in% c("977","978","979","980","981","982","983","984",
"985","986","987","988","989","975","99")))
for(i in 1:nrow(data)) {
insert_into_communes (connexion,  data[i,"code"], data[i,"libelle"],
data[i,"codePostal"], data[i,"codeDepartement"])
}
}
#---------------------------- fonction finale --------------------------------------------#
# insère dans la base le reférentiel des deparetement, regions et communes
mise_a_jour_referentiel<-function (connexion, token){
mise_a_jour_regions(connexion,token)
mise_a_jour_departement(connexion,token)
mise_a_jour_communes(connexion,token)
}
#---------------------------- fonction finale --------------------------------------------#
# recupère les données concernant les offres de l'API et les insère dans la base
# si dateMaj est NA, la fonction recupère toutes les données disponibles sinon le diffrence suelement(recupere uniquement les offres ayant une date > max date de creation de la base )
data_from_api_to_bdd<-function (connexion,mot_cle, token, dateMaj){
#préparer le paramètre
mot_cle = str_replace_all(mot_cle," ","+")
# Nous ne pouvons recupérer que 150 ligne du resultat à chaque appel pour l' API
# le paramètre "range" nous permet de faire plusieurs appels par tranche de 150 ligne à chaque fois
index_min=0
index_max=149
# si la date de la dernière mise à jours n'est pas NA, l'ajouter comme paramère dans l'url de l'appel
suffixurl=""
if(is.na(dateMaj)){
print("Date de dernière mise à jour est NULL")
}else{
print(paste("Dernière mise à jour de la base: ",dateMaj, sep=""))
now = format(Sys.time(), "%Y-%m-%dT%H:%M:%OSZ")
suffixurl=paste("&minCreationDate=",dateMaj,"&maxCreationDate=",now,sep="")
}
#répeter tant que l'appel de webservice envoie le code 206: qui veut dire que il y a encore des lignes
# qui correspond à la recherche mais seulement 150 lignes sont retournées à chaque fois pour l'API
repeat{
#construction de l'URL
url = paste("https://api.emploi-store.fr/partenaire/offresdemploi/v2/offres/search?motsCles=",
mot_cle,
"&range=",
as.character(index_min),
"-",
as.character(index_max),
suffixurl,
sep=""
)
#recupérer les données
request_data <-httr::GET(url,add_headers(Authorization = token))
print(url)
print(status_code(request_data))
if(status_code(request_data)==206 | status_code(request_data)==200 ){
#
df=as.data.frame(fromJSON(content(request_data,as="text", encoding = "UTF-8"), flatten =TRUE)$resultats)
df = Add_categorie(df)
insert_data_int_bdd(connexion,df)
#si le code different de 206 ou 200, arrêter la boucle (il n'y plus de résultat ou erreur)
}else{
break
}
# passer à la tranche suivante
index_min= index_min+150
index_max= index_max+150
}
return (df)
}
#---------------------------- fonction finale --------------------------------------------#
get_token <- function (){
#donnees connexion api
id_client = "PAR_textminingr_b7458e0fe84fea218e101d411a7f861a49e551f3b9bf18c612a5059bdea3be5b"
cle_secrete = "5feab49ea00bb939a6224dfb224b13d895b7ea21021a67c6468b5a663f410eab"
# I. Generer un access token (client credentials)
request_body <- list(grant_type = "client_credentials",
client_id = id_client,
client_secret = cle_secrete,
scope = paste("api_offresdemploiv2", "o2dsoffre",
paste0("application_",id_client), sep = " "))
# recuperer le token
result_auth <- httr::POST("https://entreprise.pole-emploi.fr/connexion/oauth2/access_token",
query = list(realm = "/partenaire"),
body = request_body,
encode = "form")
auth_JSON = fromJSON(rawToChar(result_auth$content), flatten = TRUE) ; auth_JSON
token = paste("Bearer ", auth_JSON$access_token) ; token
return (token)
}
#---------------------------- fonction finale du package mysqlr--------------------------------------------#
fermerConnexion<-function(connexion){
RMySQL::dbDisconnect(connexion)
}
#Packages
# install.packages(c("httr", "jsonlite"))
# install.packages('stringr')
# install.packages("RMySQL")
#install.packages("utf8")
library(httr)
library(jsonlite)
library(stringr)
library(RMySQL)
library(utf8)
#-------------------execution exemple --------------------------#
#initialisation de la base
reset_base_donnes()
# recuperation du token
token=get_token()
#ouverture de la connexion
mydb=connect()
# table region/departement/commune
mise_a_jour_referentiel(mydb, token)
#Mise à jour de la base
maj=date_last_update(mydb)
#recuperation des mots cles de l'api
for (motcle in c("Data scientist", "Data engineer", "Data analyst"))
df= data_from_api_to_bdd(mydb,motcle,token, maj)
# fermeture de la connexion
fermerConnexion(mydb)
library(shiny)
library(shinydashboard)
library(dplyr)
library(lubridate)
library(tidyverse)
library(tidytext)
library(tm)
library(wordcloud)
library(FactoMineR)
library(factoextra)
library(gplots)
library(graphics)
library(corrplot)
library(questionr)
ui = shinyUI(fluidPage(
dashboardPage(skin = "purple",
title = "Application - Text Mining", # Titre dans le navigateur
dashboardHeader(title = "Application - Text mining", titleWidth = 300),
dashboardSidebar(width = 300,
sidebarMenu(
menuItem("Connexion à l'API", tabName = "page1"),
menuItem("Analyse par métier", tabName = "page2"),
menuItem("Analyse des compétences", tabName = "page3"),
menuItem("Statistiques descriptives", tabName = "page4"),
menuItem("Cartographie des offres", tabName = "page5")
)
),
dashboardBody(
tabItems(
tabItem(tabName = "page1",
fluidRow(
column(12, h2("Importation des données", align = "center")),
column(12, h4("I. Alimentation de la base de données à l'aide de l'API pôle emploi")),
column(12, h4("II. Récupération des données"))
)),
tabItem(tabName = "page2",
#titlePanel("Analyse par métier"),
fluidRow(
column(12, h2("Analyse par métier", align = "center")),
column(12, sliderInput("nb", "Nombre de mots:", min = 5, max = 100, value = 20)),
column(4, h4("DATA ANALYST"), plotOutput("wordcloud_DATA_ANALYST")),
column(4, h4("DATA SCIENTIST"), plotOutput("wordcloud_DATA_SCIENTIST")),
column(4, h4("DATA ENGINEER"), plotOutput("wordcloud_DATA_ENGINEER"))
)),
tabItem(tabName = "page3",
fluidRow(
column(12, h2("Analyse des compétences", align = "center")),
column(12, checkboxGroupInput("competences", "Séléction des compétences à analyser :",
choices = c("r", "python", "sql", "spark", "powerbi", "cloud","bigdata", "algorithme",
"basededonnees", "businessintelligence", "modele", "machinelearning",
"decision", "sas", "azure", "aws", "java","scala", "reporting", "anglais", "statistique"),
selected = c("r", "python", "sql", "spark", "powerbi", "cloud","bigdata", "algorithme",
"basededonnees", "businessintelligence", "modele", "machinelearning",
"decision", "sas", "azure", "aws", "java","scala", "reporting", "anglais", "statistique"),
inline = TRUE)),
column(12, actionButton("OK1", "OK")),
column(12, sliderInput("top", "Top des compétences par métier:", min = 1, max = 15, value = 5)),
column(4, h4("DATA ANALYST"), dataTableOutput("top_competences_DATA_ANALYST")),
column(4, h4("DATA SCIENTIST"), dataTableOutput("top_competences_DATA_SCIENTIST")),
column(4, h4("DATA ENGINEER"), dataTableOutput("top_competences_DATA_ENGINEER")),
column(12, h2("Analyse Factorielle des Correspondances", align = "center")),
column(12, plotOutput("afc_plot"))
)),
tabItem(tabName = "page4", "Test page 4"),
tabItem(tabName = "page5", "Test page 5")
)
)
)
))
server = shinyServer(function(input, output) {
# A executer une seule fois :
# reset_baseb_donnes()
mydb=connect() # Ouverture de la connexion
df1 = dbFetch(dbSendQuery(mydb,"SELECT categorie, intitule_offre, description_offre from offre_emploi;"))
Encoding(df1[["intitule_offre"]]) = "UTF-8"
Encoding(df1[["description_offre"]]) = "UTF-8"
dbDisconnect(mydb) # Fermeture de la connexion
##############################################################################
## Utile pour tout
##############################################################################
Unaccent <- function(text) {
text <- gsub("['`^~\"]", " ", text)
text <- iconv(text, to="ASCII//TRANSLIT//IGNORE")
text <- gsub("['`^~\"]", "", text)
return(text)
}
Nettoyage_dfdescription_offre = function(dfdescription_offre){
# Nettoyage
dfdescription_offre = Unaccent(dfdescription_offre)
dfdescription_offre = str_to_lower(dfdescription_offre)
dfdescription_offre  <- gsub("\n"," ",dfdescription_offre)
dfdescription_offre  <- gsub("[0-9]"," ",dfdescription_offre)
dfdescription_offre  <- gsub("[[:punct:]]"," ",dfdescription_offre)
# Correction orthographique & Concatenation mots
dfdescription_offre  <- gsub("model[[:alnum:]]*( )","modele ",dfdescription_offre)
dfdescription_offre  <- gsub("developp[[:alnum:]]*( )","developpement ",dfdescription_offre)
dfdescription_offre  <- gsub("accompagn[[:alnum:]]*( )","accompagner ",dfdescription_offre)
dfdescription_offre  <- gsub("particip[[:alnum:]]*( )","participer ",dfdescription_offre)
dfdescription_offre  <- gsub("amelior[[:alnum:]]*( )","ameliorer ",dfdescription_offre)
dfdescription_offre  <- gsub("transform[[:alnum:]]*( )","transformer ",dfdescription_offre)
dfdescription_offre  <- gsub(" reportings "," reporting ",dfdescription_offre)
dfdescription_offre  <- gsub(" big data "," bigdata ",dfdescription_offre)
dfdescription_offre  <- gsub(" apprentissage automatique "," machinelearning ",dfdescription_offre)
dfdescription_offre  <- gsub(" machine learning "," machinelearning ",dfdescription_offre)
dfdescription_offre  <- gsub(" mise en place "," miseenplace ",dfdescription_offre)
dfdescription_offre  <- gsub(" mise en oeuvre "," miseenplace ",dfdescription_offre)
dfdescription_offre  <- gsub(" mettre en place "," miseenplace ",dfdescription_offre)
dfdescription_offre  <- gsub(" power bi "," powerbi ",dfdescription_offre)
dfdescription_offre  <- gsub(" business intelligence ","businessintelligence",dfdescription_offre)
dfdescription_offre  <- gsub(" bi "," businessintelligence ",dfdescription_offre)
#dfdescription_offre  <- gsub("businessintelligencedata","businessintelligence",dfdescription_offre)
dfdescription_offre  <- gsub(" base de donnees "," basededonnees ",dfdescription_offre)
dfdescription_offre  <- gsub(" bases de donnees "," basededonnees ",dfdescription_offre)
dfdescription_offre  <- gsub(" dataviz "," datavisualisation ",dfdescription_offre)
dfdescription_offre  <- gsub(" data visualisation "," datavisualisation ",dfdescription_offre)
dfdescription_offre  <- gsub(" visualisation de donnees "," datavisualisation ",dfdescription_offre)
dfdescription_offre  <- gsub(" web scraping "," webscraping ",dfdescription_offre)
dfdescription_offre  <- gsub(" data management "," datamanagement ",dfdescription_offre)
dfdescription_offre  <- gsub(" non supervise "," nonsupervise ",dfdescription_offre)
dfdescription_offre  <- gsub(" non supervises "," nonsupervise ",dfdescription_offre)
dfdescription_offre  <- gsub(" supervises "," supervise ",dfdescription_offre)
dfdescription_offre  <- gsub(" etudes "," etude ",dfdescription_offre)
dfdescription_offre  <- gsub(" besoins "," besoin ",dfdescription_offre)
dfdescription_offre  <- gsub(" solutions "," solution ",dfdescription_offre)
dfdescription_offre  <- gsub(" missions "," mission ",dfdescription_offre)
dfdescription_offre  <- gsub(" indicateurs "," indicateur ",dfdescription_offre)
dfdescription_offre  <- gsub(" kpis "," kpi ",dfdescription_offre)
dfdescription_offre  <- gsub(" catalogues "," catalogue ",dfdescription_offre)
dfdescription_offre  <- gsub(" dashbords "," dashbord ",dfdescription_offre)
dfdescription_offre  <- gsub(" decisions "," decision ",dfdescription_offre)
dfdescription_offre  <- gsub(" statistiques "," statistique ",dfdescription_offre)
dfdescription_offre  <- gsub(" projets "," projet ",dfdescription_offre)
dfdescription_offre  <- gsub(" algorithmes "," algorithme ",dfdescription_offre)
dfdescription_offre  <- gsub(" analyses "," analyse ",dfdescription_offre)
dfdescription_offre  <- gsub(" analyser "," analyse ",dfdescription_offre)
dfdescription_offre  <- gsub(" clients "," client ",dfdescription_offre)
dfdescription_offre  <- gsub(" techniques "," technique ",dfdescription_offre)
dfdescription_offre  <- gsub(" informations "," information ",dfdescription_offre)
dfdescription_offre  <- gsub(" resultats "," resultat ",dfdescription_offre)
#dfdescription_offre  <- gsub(" missions "," resultat ",dfdescription_offre)
return(dfdescription_offre)
}
wordcloud_metier = function(metier){
df = df_desc_cat() %>% filter(categorie == metier)
# Nettoyage
df$description_offre = Nettoyage_dfdescription_offre(df$description_offre)
# Création du corpus
corpus = tibble(line = 1:nrow(df), desc = df$description_offre)
res = corpus %>%
unnest_tokens(output = word, input = desc) %>%
filter(!word %in% Unaccent(stopwords("french"))) %>%
filter(!word %in% stopwords_spe) %>%
filter(!word %in% letters)
dico = res %>% count(word, sort = TRUE) %>% arrange(-n)
dico = as.data.frame(head(dico, input$nb))
set.seed(0)
wordcloud(words = dico$word, freq = dico$n, color = brewer.pal(8, "Dark2"))
}
top_competences_metier = function(metier){
df = df_desc_cat() %>% filter(categorie == metier)
# Nettoyage
df$description_offre = Nettoyage_dfdescription_offre(df$description_offre)
# Création du corpus
corpus = tibble(line = 1:nrow(df), desc = df$description_offre)
res = corpus %>%
unnest_tokens(output = word, input = desc) %>%
filter(!word %in% Unaccent(stopwords("french"))) %>%  # Enlever les stopwords francais
filter(!word %in% stopwords_spe) %>%                  # Enlever les stopwords_spe
filter(!word %in% setdiff(letters, "r"))              # Enlever les lettres seules saufs "r"
dico = res %>% count(word, sort = TRUE) %>% arrange(-n)
dico_bis = dico[dico$word %in% input$competences,]
dico_bis$Freq = round((dico_bis$n/sum(dico_bis$n))*100, 2)
dico_bis = dico_bis %>% select(-n)
colnames(dico_bis) = c("Compétences", "Fréquence d'apparition (en %)")
head(dico_bis, input$top)
}
# Liste des stopwords spécifiques
stopwords_spe = c("data", "donnees", "donnee", "cadre", "profil", "formation", "science", "suivante", "suivantes",
"france", "chez", "minimum", "depuis", "jour", "departement", "asie", "pays",
"scientists", "scientist", "scientiste", "analyst", "analysts", "engineer", "engineers", "poste",
"descriptif", "description", "remuneration", "eur", "ans","recrutement", "salaire",
"recherchons", "recherche", "rejoignez", "secteur", "reference", "recrute", "venez",
"bnp", "paribas", "fffd", "carrefour", # Ajouter les noms d'entreprises
"selon", "alors", "autour", "avant","numero", "toute",
"etre", "bac", "cdi", "cdd", "travaille", "notamment", "type", "egalement",
"quoi","vue", "fr", "bien", "different", "differents",
"afin", "plus", "etc", "www", "sein","deja", "mieux","ca",
"doit", "donne", "faire", "fait", "jusqu", "bon", "bonnes","metier", "metiers", "travail",
"bonne", "tous", "toutes", "re", "ainsi", "aussi", "tant", "travailler", "travaillez", "autres",
"sous", "chaque", "personnes", "points", "rh", "carriere","emploi", "plein", "pole", "ci",
"compte", "langages", "rejoindre", "tout", "titre", "avoir", "tres", "lors","aujourd", "hui",
"skill","skills", "partie", "demande", "group", "massy", "demain", "enfin", "region", "ville", "prime",
"niveau", "nouveaux", "nouvelles", "mise", "place", "offre","offres",
"produits","produit", "collaborateurs","collaborateur", "entreprise", "environnement","charge",
"mission", "projet",
"outils","groupe","equipe","equipes","real","connaissance","connaissances","competence","competences","qualite","qualites",
"estate", "experience","capacite","capacites","necessaire","necessaires","forces","force","quotidien","services","service")
# Dataframe : Catégorie - Intitule - Description
df_desc_cat <- reactive({
# df <- read.csv("df_textmining.csv", encoding = "latin1")
# df = df %>% select(-X)
df1
})
output$top_competences_DATA_ANALYST <- renderDataTable({
top_competences_metier(metier = "DATA ANALYST")
}, options = list(searching = FALSE, paging = FALSE))
output$top_competences_DATA_SCIENTIST <- renderDataTable({
top_competences_metier(metier = "DATA SCIENTIST")
}, options = list(searching = FALSE, paging = FALSE))
output$top_competences_DATA_ENGINEER <- renderDataTable({
top_competences_metier(metier = "DATA ENGINEER")
}, options = list(searching = FALSE, paging = FALSE))
output$afc_plot <- renderPlot({
df = df_desc_cat()
# Nettoyage
df$description_offre = Nettoyage_dfdescription_offre(df$description_offre)
# Création du corpus
corpus = tibble(line = 1:nrow(df), desc = df$description_offre)
res = corpus %>%
unnest_tokens(output = word, input = desc) %>%
filter(!word %in% Unaccent(stopwords("french"))) %>%  # Enlever les stopwords francais
filter(!word %in% stopwords_spe) %>%                  # Enlever les stopwords_spe
filter(!word %in% setdiff(letters, "r"))              # Enlever les lettres seules saufs "r"
dico = res %>% count(word, sort = TRUE) %>% arrange(-n)
# Comptage des termes par document
compte = res %>%
group_by(line, word) %>%
summarize(freq=n())
# Matrice termes documents
mtd = as.matrix(compte %>%  cast_dtm(document = line, term = word, value = freq))
app_termes = apply(mtd, 2, function(x){sum(x>1)})
mtd_filtre = as.data.frame(mtd[,app_termes > 10])
# Construction de la table de contingence
contingence = aggregate.data.frame(x = mtd_filtre, by = list(df$categorie), sum)
rownames(contingence) = contingence$Group.1
contingence = contingence %>% select(-Group.1)
contingence = contingence[, colnames(contingence) %in% input$competences]
# calcul de l'AFC
res.ca <- CA(contingence, graph = FALSE)
# Graphique AFC
fviz_ca_biplot (res.ca, repel = TRUE, title	= "Analyse Factorielle des Correspondances")
})
#-----------------------------------------------------------------------------
# Wordcloud par metier
#-----------------------------------------------------------------------------
output$wordcloud_DATA_ANALYST <- renderPlot({
wordcloud_metier(metier = "DATA ANALYST")
})
output$wordcloud_DATA_SCIENTIST <- renderPlot({
wordcloud_metier(metier = "DATA SCIENTIST")
})
output$wordcloud_DATA_ENGINEER <- renderPlot({
wordcloud_metier(metier = "DATA ENGINEER")
})
})
shinyApp(ui, server)
runApp('~/GitHub/M2_Text_Mining')
runApp()
runApp('~/GitHub/M2_Text_Mining')
